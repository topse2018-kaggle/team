{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score \n",
    "from sklearn.model_selection import learning_curve, StratifiedKFold, train_test_split\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Describe Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Feature Names: \n",
    "\n",
    " ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
    " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
    " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
    " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
    " 'smoothness error' 'compactness error' 'concavity error'\n",
    " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
    " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
    " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
    " 'worst concave points' 'worst symmetry' 'worst fractal dimension']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plotOne = sns.FacetGrid(sizeMeasurements, hue=\"target\",aspect=2.5)\n",
    "plotOne.map(sns.kdeplot,'mean area',shade=True)\n",
    "plotOne.set(xlim=(0, sizeMeasurements['mean area'].max()))\n",
    "plotOne.add_legend()\n",
    "plotOne.set_axis_labels('mean area', 'Proportion')\n",
    "plotOne.fig.suptitle('Area vs Diagnosis (Blue = Malignant; Orange = Benign)')\n",
    "plt.show()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plotTwo = sns.FacetGrid(sizeMeasurements, hue=\"target\",aspect=2.5)\n",
    "plotTwo.map(sns.kdeplot,'mean concave points',shade= True)\n",
    "plotTwo.set(xlim=(0, sizeMeasurements['mean concave points'].max()))\n",
    "plotTwo.add_legend()\n",
    "plotTwo.set_axis_labels('mean concave points', 'Proportion')\n",
    "plotTwo.fig.suptitle('# of Concave Points vs Diagnosis (Blue = Malignant; Orange = Benign)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFeature Correlation:\\n\")\n",
    "g = sns.heatmap(X_train.corr(),cmap=\"BrBG\",annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retain only features that are not correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeMeasurements2 = sizeMeasurements.drop(['mean radius','mean perimeter',\n",
    " 'mean smoothness', 'mean compactness', 'mean concavity',\n",
    " 'mean concave points', 'mean fractal dimension',\n",
    " 'radius error', 'texture error', 'perimeter error', 'area error',\n",
    " 'smoothness error', 'compactness error', 'concavity error',\n",
    " 'concave points error', 'symmetry error', 'fractal dimension error',\n",
    " 'worst radius', 'worst perimeter', \n",
    " 'worst smoothness', 'worst compactness', \n",
    " 'worst concave points', 'worst symmetry', 'worst fractal dimension','worst texture', 'worst area',\n",
    " 'worst concavity'], axis=1)\n",
    "X2 = sizeMeasurements2[sizeMeasurements2.columns[:-1]]\n",
    "y2 = sizeMeasurements2.target\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X2, y2, test_size=0.2)\n",
    "print('\\n Feature Names: \\n\\n', X2.columns.values, \"\\n\")\n",
    "print(\"\\nFeature Correlation:\\n\")\n",
    "g = sns.heatmap(X_train2.corr(),cmap=\"BrBG\",annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " use PCA transformation to select features and reduce feature correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X3=X\n",
    "y3=y\n",
    "variance_pct = 5 # Minimum percentage of variance we want to be described by the resulting transformed components\n",
    "pca = PCA(n_components=variance_pct) # Create PCA object\n",
    "X_transformed = pca.fit_transform(X3,y3) # Transform the initial features\n",
    "X3pca = pd.DataFrame(X_transformed) # Create a data frame from the PCA'd data\n",
    "X_train3, X_test3, Y_train3, Y_test3 = train_test_split(X3pca, y3, test_size=0.2)\n",
    "print('\\n Feature Names: \\n\\n', X3pca.columns.values, \"\\n\")\n",
    "#print('First Few Values, After PCA: \\n\\n,',X3pca.head(),'\\n\\n')\n",
    "print(\"\\nFeature Correlation:\\n\")\n",
    "g = sns.heatmap(X_train3.corr(),cmap=\"BrBG\",annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = tree.DecisionTreeClassifier(max_depth=3,min_samples_leaf=12)\n",
    "clf1.fit(X_train, Y_train)\n",
    "clf2 = tree.DecisionTreeClassifier(max_depth=3,min_samples_leaf=12)\n",
    "clf2.fit(X_train2, Y_train2)\n",
    "clf3 = tree.DecisionTreeClassifier(max_depth=3,min_samples_leaf=12)\n",
    "clf3.fit(X_train3, Y_train3)\n",
    "print('Accuracy of Decision Tree classifier on original training set: {:.2f}'.format(clf1.score(X_train, Y_train)))\n",
    "print('Accuracy of Decision Tree classifier on original test set: {:.2f}'.format(clf1.score(X_test, Y_test)))\n",
    "print('Accuracy of Decision Tree classifier on reduced training set: {:.2f}'.format(clf2.score(X_train2, Y_train2)))\n",
    "print('Accuracy of Decision Tree classifier on reduced test set: {:.2f}'.format(clf2.score(X_test2, Y_test2)))\n",
    "print('Accuracy of Decision Tree classifier on PCA-transformed training set: {:.2f}'.format(clf3.score(X_train3, Y_train3)))\n",
    "print('Accuracy of Decision Tree classifier on PCA-transformed test set: {:.2f}'.format(clf3.score(X_test3, Y_test3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names1 = X.columns.values\n",
    "feature_names2 = X2.columns.values\n",
    "feature_names3 = X3pca.columns.values\n",
    "\n",
    "def plot_decision_tree1(a,b):\n",
    "    dot_data = tree.export_graphviz(a, out_file=None, \n",
    "                             feature_names=b,  \n",
    "                             class_names=['Malignant','Benign'],  \n",
    "                             filled=False, rounded=True,  \n",
    "                             special_characters=False)  \n",
    "    graph = graphviz.Source(dot_data)  \n",
    "    return graph \n",
    "plot_decision_tree1(clf1,feature_names1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " retain only features that are not correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_tree1(clf2,feature_names2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retain only features that were produced through PCA transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Plots a learning curve. http://scikit-learn.org/stable/modules/learning_curve.html\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "dict_characters = {0: 'Malignant', 1: 'Benign'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Helper Functions for Learning Curve and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(clf2, feature_names2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X1, y1) = load_breast_cancer(return_X_y = True)\n",
    "X_train1,X_test1,Y_train1,Y_test1=train_test_split(X1,y1,random_state=0)\n",
    "clf = RandomForestClassifier(max_features=8,random_state=0)\n",
    "clf.fit(X_train1,Y_train1)\n",
    "print('Accuracy of Random Forest Classifier on training data: {:.2f}'.format(clf.score(X_train1,Y_train1)))\n",
    "print('Accuracy of Random Forest Classifier on testing data: {:.2f}'.format(clf.score(X_test1,Y_test1)))\n",
    "model = clf\n",
    "prediction = model.predict(X_test1)\n",
    "cnf_matrix = confusion_matrix(Y_test1, prediction)\n",
    "plt.show()\n",
    "plot_learning_curve(model, 'Learning Curve For RF', X_train, Y_train, (0.80,1.1), 10)\n",
    "plt.show()\n",
    "plot_confusion_matrix(cnf_matrix, classes=dict_characters,title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
